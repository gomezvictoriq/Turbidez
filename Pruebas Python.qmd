

# Importo la librer√≠a pandas para usarla
```{python}
import pandas as pd
```
#Cargo archivo csv
```{python}
df_lab = pd.read_csv(r"D:\GIT\Turbidez\datos\base_de_datos_lab.csv")
df_gis = pd.read_csv(r"D:\GIT\Turbidez\datos\base_de_datos_gis.csv")

#Tuve que poner r delante de la direccion para que me lo lea
#https://www.youtube.com/watch?v=LnH_STJ2GXo  Me ayud√≥ a entender que es un DataFrame
```

# Pruebo que me halla le√≠do bien las 2 bases de datos por separado (se puede omitir)
```{python}
print(df_lab.head())
print(df_gis.head())
```


# Del data Frame gis me quedo con las filas donde pixel=3x3

```{python}
df_gis3x3 = df_gis[(df_gis['pixel'] == '3x3')]
print(df_gis3x3.head())

```
#Combino ambas bases de datos
```{python}
df_combinado = pd.merge(df_lab, df_gis3x3, on=['latitud', 'longitud','fecha'], how='inner')

#'inner': Solo conserva las filas con coincidencias en ambos DataFrames
#Este print se puede omitir, s√≥lo lo uso para verificar
print(df_combinado.head())
```

#Hago un filtrado para quedarme solo con las filas que contenga "turb"

```{python}
df_turbidez = df_combinado[(df_combinado['param'] == 'turb')]


#En la tabla original habia pixeles vales de reflectancia para pixel de 1x1 y 3x3, nos quedamos con los de 3x3.

#Este print se puede omitir, s√≥lo lo uso para verificar, descartar pixel 1x1 y quedarme con pixel 3x3
#Nota: se conserva el √≠ndice del df_combinado_


#cuantas filas deber√≠a tener al final????? est√° bueno para saber cuando tiee que haber
print(df_turbidez.head())
```

# Elimino las columnas que no me interesan y cambio el nombre de la columna "valor" por el de "turbidez"

```{python}
df_turbidez_banda = df_turbidez.drop(columns=['longitud','latitud','punto','pixel','fecha','param'])
df_turbidez_banda.rename(columns={'valor': 'turbidez'}, inplace=True)

#df_turbidez_banda.to_csv('Turbidez y reflectancia.csv', index=False)
#Aca lo arregl√©, tengo que exportar primero el csv, en index le pongo FALSE
#Si csv est√° OK
#Este print se puede omitir, s√≥lo lo uso para verificar
print(df_turbidez_banda.head())
```



# Uso la funci√≥n pivot_table para que en las columnas sean la turbidez y las distintas bandas de Sentinel-2
 ```{python}

df_final = df_turbidez_banda.pivot_table(
    index='turbidez',
    columns='banda',
    values='reflect',  
    )

#df_final = df_final.reset_index()  #Con eso se solucion√≥ 

df_final.to_csv('Turbidez_FINAL.csv', index=True) 

#Con eso se solucion√≥ se deja en True si desactivo df_final = df_final.reset_index()

#o df_final.to_csv('Turbidez_FINAL.csv', index=Faslse) y dejo el reset index
#Cuando us√°s operaciones como groupby() o pivot_table(), Pandas suele mover una o m√°s columnas al √≠ndice del DataFrame. Esto puede ser inc√≥modo si quer√©s trabajar con esas columnas como normales.

#reset_index() convierte el √≠ndice en columnas normales, y reemplaza el √≠ndice por uno num√©rico est√°ndar (0, 1, 2...).
 ```

df_final = df.pivot_table(
    index='turbidez',       # ‚û§ Las filas ser√°n los valores √∫nicos de 'turbidez'
    columns='banda',        # ‚û§ Las columnas ser√°n los valores √∫nicos de 'banda' (por ejemplo, B01, B02...)
    values='reflect'        # ‚û§ El contenido de la tabla ser√° lo que haya en la columna 'reflect'
)


Opcional: Resetear √≠ndice si no quieres que turbidez sea √≠ndice
Si prefieres que turbidez sea una columna m√°s (no √≠ndice), puedes hacer:

Entonces la turbidez est√° en el √≠ndice, no como una columna. Por eso, al guardar con index=False, se omite.

# Creo archivo final con los valores de turbidez y reflectancia de cada banda

 

# Prueba de m√≠nimos cuadrados

## Importamos las funciones necesarias para usar este modelo lineal
 ```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```

pandas ‚Üí para leer los datos

train_test_split ‚Üí para dividir los datos en entrenamiento y validaci√≥n

LinearRegression ‚Üí para crear el modelo de regresi√≥n lineal

mean_squared_error, r2_score ‚Üí Para medir el desempe√±o del modelo (RMSE y R2)

matplotlib.pyplot ‚Üí para realizar gr√°ficos

## Cargamos los datos de inter√©s y divido en entrenamiento y validaci√≥n.

```{python}

df = pd.read_csv(r"D:\GIT\Turbidez\Turbidez_FINAL.csv")

X = df[['B04']]  
y = df['turbidez']   #ac√° tiene que ir turbidez

```

Dividimos los datos en entretrenamiento y validaci√≥n
```{python}
X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=20, shuffle=True  #hace una mezcla 
)
```

# Creo el modelo de regresi√≥n 

```{python}
regressor = LinearRegression().fit(X_train, y_train)
```

#Eval√∫o el modelo generado a partir de las m√©tricas de desempe√±o.

```{python}
y_pred = regressor.predict(X_test)
p_rmse = mean_squared_error(y_test, y_pred)
p_r2 = r2_score(y_test, y_pred)

print("RMSE", p_rmse) 
print("R2", p_r2)
```


```{python}
fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)

#Gr√°fico de entrenamiento
ax[0].plot(
    X_train,
    regressor.predict(X_train),
    linewidth=3,
    color="#17A77E",
    label="Modelo",
)


ax[0].scatter(X_train, y_train, label="Entrenamiento", color = "#9D50A6", alpha = .6)
ax[0].set(xlabel="Caracter√≠stica", ylabel="Objetivo", title="Conjunto de entrenamiento")
ax[0].legend()

#Gr√°fico de validaci√≥n
ax[1].plot(X_test, y_pred, linewidth=3, color="#17A77E", label="Modelo")
ax[1].scatter(X_test, y_test, label="Validaci√≥n", color = "#9D50A6", alpha = .6)
ax[1].set(xlabel="Caracter√≠stica", ylabel="Objetivo", title="Conjunto de validaci√≥n")
ax[1].legend()



# Ecuaci√≥n de la recta
coef = regressor.coef_[0]
intercept = regressor.intercept_
equation = f"y = {coef:.2f}x + {intercept:.2f}"

# Mostrar la ecuaci√≥n en ambos subgr√°ficos (opcionalmente, puedes usar solo uno)
for a in ax:
    a.text(0.05, 0.95, equation, transform=a.transAxes,
           fontsize=10, verticalalignment='top',
           bbox=dict(boxstyle="round", facecolor="white", alpha=0.7))





fig.suptitle("Regresi√≥n lineal")

plt.show()
```


## Prueba de correlacion entre turbidez y cada banda

```{python}
import pandas as pd
import numpy as np

df= pd.read_csv(r'D:\GIT\Turbidez\Turbidez_FINAL.csv')
print (df.head())


```
Calculo el coeficiente de correlaci√≥n *r* entre la turbidez y las distintas
```{python}
correlaciones = df.corr(method='pearson')
correlacion_turbidez = correlaciones['turbidez'].filter(like='B')
print(correlacion_turbidez)

```



# Prueba con booststapp
1. Importo las librer√≠as

```{python}

import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

```

Estas bibliotecas son:

pandas: para manejar el archivo .csv y los datos en DataFrame.

numpy: para generar √≠ndices aleatorios con np.random.choice.

sklearn.linear_model: para usar la regresi√≥n lineal.

sklearn.metrics: para calcular el RMSE y el R¬≤.

2. Leer los datos


```{python}
df = pd.read_csv(r"D:\GIT\Turbidez\Turbidez_FINAL.csv")
X = df[['B05']].values
y = df['turbidez'].values


```

Se carga el archivo CSV.

X contiene la columna B05, usada como variable predictora.

y contiene la variable objetivo: turbidez.

.values transforma los DataFrame/Series a arrays de NumPy, necesarios para sklearn.

3. Configuraci√≥n del bootstrapping


```{python}
n_iteraciones = 100
n_muestras = len(df)

```

4. Inicializar listas para guardar m√©tricas
```{python}
rmse_scores = []
r2_scores = []

```

Se crean listas vac√≠as para guardar los valores de RMSE y R¬≤ de cada iteraci√≥n.

5. Ciclo de Bootstrapping


```{python}
for i in range(n_iteraciones):
    # √çndices bootstrap con reemplazo
    indices = np.random.choice(n_muestras, size=n_muestras, replace=True)
    
    # Crear muestra bootstrap
    X_boot = X[indices]
    y_boot = y[indices]

```

np.random.choice(...) genera √≠ndices aleatorios con reemplazo, es decir, se pueden repetir.

Luego se seleccionan las filas de X e y que corresponden a esos √≠ndices ‚Üí eso forma una "muestra bootstrap".

6. Entrenar el modelo

```{python}
modelo = LinearRegression().fit(X_boot, y_boot)

```

7. Predecir y calcular m√©tricas


```{python}
y_pred = modelo.predict(X)
from math import sqrt
rmse = sqrt(mean_squared_error(y, y_pred))
r2 = r2_score(y, y_pred)
```

modelo.predict(X): se predice sobre todo el dataset original (no s√≥lo la muestra bootstrap).

Se calculan:

RMSE (error cuadr√°tico medio ra√≠z)

R¬≤ (coeficiente de determinaci√≥n, qu√© tan bien predice el modelo).

üßæ 8. Guardar resultados


```{python}
rmse_scores.append(rmse)
r2_scores.append(r2)

```

9. Resultado promedio


```{python}
print(f"RMSE promedio: {np.mean(rmse_scores):.4f}")
print(f"R¬≤ promedio: {np.mean(r2_scores):.4f}")

```

(Opcional) 10. Graficar distribuci√≥n de R¬≤


```{python}
import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(r2_scores, kde=True)
plt.title("Distribuci√≥n de R¬≤ (bootstrapping)")
plt.xlabel("R¬≤")
plt.show()

```


```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# Leer los datos
df = pd.read_csv(r"D:\GIT\Turbidez\Turbidez_FINAL.csv")
X = df[['B05']].values
y = df['turbidez'].values

# Rango de valores sobre los cuales hacer predicciones
x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)

# Configuraci√≥n
n_iteraciones = 100
predicciones = []

# Bootstrap
for i in range(n_iteraciones):
    indices = np.random.choice(len(X), size=len(X), replace=True)
    X_boot = X[indices]
    y_boot = y[indices]

    modelo = LinearRegression().fit(X_boot, y_boot)
    y_pred = modelo.predict(x_range)
    predicciones.append(y_pred)

# Convertir a array y calcular promedio y desv√≠o est√°ndar
predicciones = np.array(predicciones)  # shape: (n_iteraciones, 100)
media_pred = predicciones.mean(axis=0)
std_pred = predicciones.std(axis=0)

# Graficar
plt.figure(figsize=(8, 5))

# Curva promedio
plt.plot(x_range, media_pred, color="#17A77E", label="Modelo promedio")

# Intervalo de confianza ¬±1 desviaci√≥n est√°ndar
plt.fill_between(
    x_range.ravel(),
    media_pred - std_pred,
    media_pred + std_pred,
    color="#17A77E",
    alpha=0.2,
    label="¬±1 desv√≠o est√°ndar"
)

# Datos reales
plt.scatter(X, y, color="#9D50A6", alpha=0.5, label="Datos reales")

# Ejes y leyenda
plt.xlabel("Banda 5")
plt.ylabel("Turbidez")
plt.title("Regresi√≥n lineal con bootstrapping (promedio)")
plt.legend()
plt.tight_layout()
plt.show()
```




Pruebas de correlacion 




```{python}
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from utils import run_bootstrap_linear_regression_analysis  # Asegurate de que esta funci√≥n devuelve lo necesario

# Leer los datos
Datos = pd.read_csv(r"D:\GIT\Turbidez\Datos creados\Datos_turb_banda\C1_turb_banda.csv")
y = Datos['turbidez']

# Variables
variables_fijas = ['B05']
variables_a_agregar = ['B06', 'B08', 'B07', 'B04', 'B8A', 'B03', 'B02', 'B01', 'B12', 'B11']

# Resultados
resultados = []

# Configuraci√≥n de bootstrapping
n_iteraciones_bootstrap = 200

# Entrenamiento incremental
for i in range(len(variables_a_agregar) + 1):
    variables_usadas = variables_fijas + variables_a_agregar[:i]
    X = Datos[variables_usadas].values

    # Divisi√≥n entrenamiento/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, shuffle=True, random_state=42
    )

    # Bootstrapping: obtener coeficientes promedio y m√©tricas de entrenamiento
    coef_prom, intercept_prom, r2_train_boot, rmse_train_boot = run_bootstrap_linear_regression_analysis(
    X_train, y_train.to_numpy(), n_iteraciones=n_iteraciones_bootstrap)


    # Modelo final con coeficientes promedio
    modelo_final = LinearRegression()
    modelo_final.coef_ = coef_prom
    modelo_final.intercept_ = intercept_prom

    # Predicci√≥n sobre testeo
    y_pred = modelo_final.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    # R¬≤ ajustado
    n_obs = len(y_test)
    n_vars = X_test.shape[1]
    r2_ajustado = 1 - (1 - r2) * (n_obs - 1) / (n_obs - n_vars - 1)

    # AIC
    residuals = y_test - y_pred
    rss = np.sum(residuals ** 2)
    k = X_test.shape[1] + 1  # +1 por el intercepto
    aic = n_obs * np.log(rss / n_obs) + 2 * k

    # Guardar resultados
    resultados.append({
        "variables": ", ".join(variables_usadas),
        "num_variables": len(variables_usadas),
        "R¬≤_train (bootstrap)": r2_train_boot,
        "RMSE_train (bootstrap)": rmse_train_boot,
        "R¬≤_test": r2,
        "R¬≤-ajustado": r2_ajustado,
        "RMSE_test": rmse,
        "AIC": aic
    })

# Convertir a DataFrame
df_resultados = pd.DataFrame(resultados)
print(df_resultados)

```




Paso 1: Funci√≥n de selecci√≥n autom√°tica con AIC (stepwise)
```{python}
import statsmodels.api as sm
import pandas as pd
import numpy as np

def stepwise_selection(X, y, 
                       initial_list=[], 
                       threshold_in=0.01, 
                       threshold_out=0.05, 
                       verbose=True):
    included = list(initial_list)
    while True:
        changed = False
        # forward step
        excluded = list(set(X.columns) - set(included))
        new_pval = pd.Series(index=excluded)
        for new_column in excluded:
            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()
            new_pval[new_column] = model.pvalues[new_column]
        best_pval = new_pval.min()
        if best_pval < threshold_in:
            best_feature = new_pval.idxmin()
            included.append(best_feature)
            changed = True
            if verbose:
                print(f"Agregado: {best_feature} (p={best_pval:.4f})")

        # backward step
        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()
        pvalues = model.pvalues.iloc[1:]  # sin el intercepto
        worst_pval = pvalues.max()
        if worst_pval > threshold_out:
            worst_feature = pvalues.idxmax()
            included.remove(worst_feature)
            changed = True
            if verbose:
                print(f"Eliminado: {worst_feature} (p={worst_pval:.4f})")

        if not changed:
            break

    return included

```

üìå Paso 2: Aplicar selecci√≥n a tus datos

```{python}
# Asumiendo que tus datos est√°n en un DataFrame llamado Datos
# y que turbidez es tu variable objetivo

Datos = pd.read_csv(r"D:\GIT\Turbidez\Datos creados\Datos_turb_banda\C1_turb_banda.csv")

X = Datos[['B05', 'B06', 'B08', 'B07', 'B04', 'B8A', 'B03', 'B02', 'B01', 'B11', 'B12']]
y = Datos['turbidez']

# Selecci√≥n autom√°tica
vars_seleccionadas = stepwise_selection(X, y)

print("\nVariables seleccionadas:", vars_seleccionadas)

```

Paso 3: Validaci√≥n cruzada del modelo seleccionado

```{python}
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from numpy import mean

X_sel = Datos[vars_seleccionadas].values
y_sel = y.values

# Modelo lineal
model = LinearRegression()
cv = KFold(n_splits=5, shuffle=True, random_state=42)

# MSE negativo ‚Üí se invierte para obtener el RMSE
rmse_scores = -cross_val_score(model, X_sel, y_sel, scoring='neg_root_mean_squared_error', cv=cv)
r2_scores = cross_val_score(model, X_sel, y_sel, scoring='r2', cv=cv)

print(f"\nCV RMSE promedio: {mean(rmse_scores):.2f}")
print(f"CV R¬≤ promedio: {mean(r2_scores):.4f}")

```

üìå Paso 4: Evaluar AIC del modelo final (opcional)

```{python}
X_const = sm.add_constant(Datos[vars_seleccionadas])
modelo_final = sm.OLS(y, X_const).fit()
print(f"AIC del modelo final: {modelo_final.aic:.2f}")
print(modelo_final.summary())

```

```{python}
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm

# Asumiendo que tus datos est√°n en un DataFrame llamado Datos
X = Datos[['B05', 'B04']]
y_real = Datos['turbidez']

# Agregar constante y ajustar modelo
X_const = sm.add_constant(X)
modelo = sm.OLS(y_real, X_const).fit()
y_est = modelo.predict(X_const)

# Gr√°fico
plt.figure(figsize=(6,6))
sns.scatterplot(x=y_real, y=y_est, color='blue', s=60)
plt.plot([y_real.min(), y_real.max()], [y_real.min(), y_real.max()], 'r--')  # l√≠nea ideal
plt.xlabel('Turbidez Real')
plt.ylabel('Turbidez Estimada')
plt.title('Turbidez: Real vs Estimada (Modelo con B05 y B04)')
plt.grid(True)
plt.tight_layout()
plt.show()

```


¬øPor qu√© no se detiene?
Porque tus variables probablemente est√©n:

Altamente informativas

No muy colineales (o no lo suficiente como para que el error deje de bajar)

Y el conjunto de datos tiene suficientes muestras para compensar la penalizaci√≥n

Pero ojo:
AIC no detecta sobreajuste tan bien como validaci√≥n cruzada.

Pod√©s tener un modelo con AIC bajo pero poca capacidad de generalizaci√≥n.




# Modelo con cocientes
```{python}
#| code-fold: true
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from utils import run_bootstrap_linear_regression_analysis

# Leer datos
df = pd.read_csv(r"D:\GIT\Turbidez\Datos creados\Datos_turb_banda\C1_turb_banda.csv")

# Evitar divisi√≥n por cero en B06


df['B03_mod'] = df['B03'].replace(0, 1e-6)
df['B04_mod'] = df['B04'].replace(0, 1e-6)

# Crear cociente
df['B06_div_B03_mod'] = df['B06'] / df['B03_mod']
df['B08_div_B03_mod'] = df['B08'] / df['B03_mod']
#df['B06_div_B04_mod'] = df['B06'] / df['B04_mod']



# Usar el cociente como variable predictora
variables = ['B06_div_B03_mod','B08_div_B03_mod']
X_completo = df[variables].values
y_completo = df['turbidez'].values


# Separar entrenamiento y testeo
X_train, X_test, y_train, y_test = train_test_split(
    X_completo, y_completo, test_size=0.25, random_state=42
)

# Ejecutar bootstrapping
n_iteraciones_config = 1000
coef_prom, intercept_prom, r2_train_boot, rmse_train_boot = \
    run_bootstrap_linear_regression_analysis(X_train, y_train, n_iteraciones=n_iteraciones_config)

# Modelo final con coeficientes promedio
modelo_final_promedio = LinearRegression()
modelo_final_promedio.coef_ = coef_prom
modelo_final_promedio.intercept_ = intercept_prom

# Predicci√≥n sobre entrenamiento y test
y_train_pred = modelo_final_promedio.predict(X_train)
y_test_pred = modelo_final_promedio.predict(X_test)

# M√©tricas en testeo
r2_test = r2_score(y_test, y_test_pred)
rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))

# ------------------ Gr√°fico con estilo personalizado ------------------ #
plt.figure(figsize=(5, 5))

# Entrenamiento
plt.scatter(y_train, y_train_pred, color="#9D50A6", alpha=0.5, label="Datos de entrenamiento", marker='o')

# Test
plt.scatter(y_test, y_test_pred, color="red", alpha=0.7, label="Datos de testeo", marker='^')

# L√≠nea ideal
min_val = min(np.min(y_train), np.min(y_test))
max_val = max(np.max(y_train), np.max(y_test))
plt.plot([min_val, max_val], [min_val, max_val], '--', color="#17A77E", lw=2, label="L√≠nea ideal")

# L√≠nea de tendencia sobre test
coef_linea = np.polyfit(y_test, y_test_pred, 1)  # [pendiente, intercepto]
x_tendencia = np.linspace(min_val, max_val, 100)
y_tendencia = coef_linea[0] * x_tendencia + coef_linea[1]
plt.plot(x_tendencia, y_tendencia, '-', color='black', lw=2, label="L√≠nea de tendencia")

plt.xlabel("Turbidez real (NTU)")
plt.ylabel("Turbidez estimada (NTU)")
plt.title(
    f"Regresi√≥n lineal con Bootstrapping ({n_iteraciones_config} modelos)\n"
    f"R¬≤ entrenamiento: {r2_train_boot:.4f}, RMSE: {rmse_train_boot:.4f} | "
    f"R¬≤ testeo: {r2_test:.4f}, RMSE: {rmse_test:.4f}"
)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

```