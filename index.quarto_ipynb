{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Algoritmo para la estimación de la turbidez sobre el Río Paraná\"\n",
        "format: \n",
        "  html:\n",
        "    number-sections: true\n",
        "    toc: true\n",
        "    embed-resources: true\n",
        "    crossrefs-hover: false\n",
        "    lang: es\n",
        "    bibliography: bibliografia/bibliografia.bib\n",
        "    csl: bibliografia/ieee.csl\n",
        "    theme: cosmo \n",
        "date: last-modified\n",
        "author:\n",
        "  - name: Víctor Gustavo Gómez\n",
        "    corresponding: true\n",
        "    email: gomezvictoriq@ca.frre.utn.edu.ar\n",
        "    affiliations:\n",
        "      - name: GISTAQ (UTN-FRRe)\n",
        "        url: https://www.instagram.com/gistaq.utn/\n",
        "abstract: |\n",
        "  Este sitio web contiene información sobre la estimación de la turbidez por teledetección en la cuenca media del Río Paraná. \n",
        "  La turbidez es uno parámetros de interés dentro proyecto Estimar indicadores de calidad de agua en la cuenca media del río Paraná para el desarrollo de un algoritmo mediante técnicas de teledetección satelital (MSECRE0008604), desarrollado por el Grupo de Investigación Sobre Temas Ambientales y Químicos (GISTAQ) de la Universidad Tecnológica Nacional Facultad Regional Resistencia (UTN-FRRe).\n",
        "\n",
        "  Se utilizarán imágenes del satélite Sentinel-2 con corrección automática, de las cuales se obtiene la reflectancia de superficie del agua. Se buscará la relación entre la reflectancia y la turbidez por métodos de regresión tradionales y machine learning. Una vez obtenido el algoritmo que relacione ambas propiedades, se desarrollaran mapas de distribución espacial.\n",
        "  \n",
        "keywords:\n",
        "  - GISTAQ\n",
        "  - UTN\n",
        "  - FRRe\n",
        "  - Algoritmo\n",
        "  - Turbidez\n",
        "  - Machine learning\n",
        "  - Teledetección\n",
        "---\n",
        "\n",
        "# Turbidez\n",
        "\n",
        "La turbidez se refiere a la opacidad o falta de claridad en un líquido provocada por la presencia de partículas suspendidas. Este fenómeno es un indicador clave en el monitoreo de la calidad del agua y su influencia en diferentes ecosistemas es significativa.\n",
        "\n",
        "La turbidez es un indicador de la calidad del agua, reflejando la presencia de partículas en suspensión. Su medición es crucial para garantizar la potabilidad del agua y la salud de los ecosistemas acuáticos. Este fenómeno puede ser resultado de diversas causas, como la erosión del suelo, la actividad biológica y la contaminación. La comprensión de la turbidez y su impacto es esencial para la gestión de recursos hídricos y la protección del medio ambiente.\n",
        "\n",
        "La turbidez viene determinada por la dispersión de la luz causada por la materia suspendida en el agua, se obtiene normalmente mediante un turbidímetro, que proporciona medidas en Nephelometric Turbidity Unit (NTU) y mide la dispersión de un rayo de luz en el agua a 90º de la luz incidente [@Delegido2019].\n",
        "\n",
        "Muchas propiedades, como la clorofila-a (Chl-a), sólidos suspendidos totales (SST) y la materia orgánica disuelta coloreada (CDOM), se utilizan a menudo como indicadores del estado del agua. Estos constituyentes del agua a su vez son responsables de la turbidez.\n",
        "\n",
        "Existe una fuerte correlación entre turbidez y sólidos suspendidos totales, por lo que se puede estimar SST a partir de la turbidez. Por lo general, es una relación directa, a mayor concentración de SST mayor turbidez.\n",
        "\n",
        "Existe una relación inversa entre la Turbidez y la profundidad del disco de Secchi (a valores bajos de secchi mayor turbidez), por lo que también se puede estimar turbidez a partir de mediciones de disco de secchi.\n",
        "\n",
        "## Métodos tradicionales\n",
        "\n",
        ":::: {.content-visible when-format=\"html\"}\n",
        "\n",
        "::: {.column-screen-right}\n",
        "<!-- TODO corregir <br> de la ecuación -->\n",
        "| Ecuación | Bandas (nm) | Métricas | Aguas | Plataforma | Referencia |\n",
        "|:-:|:--|:--|:--|:--|:-:|\n",
        "| $1.559e^{35.533 \\cdot B03} \\\\ 1.879e^{37.745(B03 \\cdot B5)/(B04+B12)}$ | B03, B04, B05, B12 | $R^{2}$, RMSE, MAE | Lago^[0,83 - 112,26 NTU.] | Sentinel-2 | @Ma2021 |\n",
        "| $2677.2 \\cdot B04^{1.856}$ | B04 | $R^{2}$, RMSE, Bias | Interiores variadas^[2,3 - 107,02 NTU.] | Landsat-8 | @Hossain2021 |\n",
        "| $969-1.5468 \\cdot R_{1200nm}+2.07 \\frac{B8A}{B02}$ | B02, B8A, 1200nm | IOA, SI, RMSE, MAE | Río^[IOA = index of agreement<br>SI = scatter index.] | Landsat-8 | @Najafzadeh2023 |\n",
        "| $y=-1.1+5.8 \\frac{B02}{B04} \\\\ y=3.896-4.186 \\frac{B02}{B03}$ | B02, B03, B04 | $R^{2}$, RMSE | Río^[20,6 - 112 NTU<br>2,3 - 15,4 NTU.] | Landsat-8 | @Allam2020 |\n",
        "| $y=37661 \\cdot B8A^{2}+1845 \\cdot B8A <br> y=531.5- \\frac{B04}{0.88}$ | B04, B8A | $R^{2}$, RMSE, MAPE | Estuario^[MAPE = Mean Absolute Percentage Error<br>0 - 1300 NTU<br>0 - 80 NTU.] | Pléiades | @Luo2020 |\n",
        "\n",
        ": Características principales de algoritmos tradicionales para la estimación de turbidez. {#tbl-turb-trad .striped .hover tbl-colwidths=\"[40,15,15,10,10]\"}\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "\n",
        "Múltiples modelos (lineal, logaritmos, inversa, cuadrática, exponencial, potencial) y plataformas (Sentinel-2, Landsat-5 y Landsat-8) emplean el cociente de bandas B04/B03 [@Shen2021].\n",
        "\n",
        "Modelos de estimación a partir de Sentinel-2 y Landsat-8 utilizan regresiones lineales, cuadráticas y logarítmicas empleando B02, B03, B04, B01 (con menos apariciones) y cocientes entre éstas [@Ouma2020].\n",
        "\n",
        "## Métodos de aprendizaje automático\n",
        "\n",
        "El aprendizaje automático es un subconjunto de la inteligencia artificial que permite que un sistema aprenda y mejore de forma autónoma, sin necesidad de una programación explícita, a través del análisis de grandes cantidades de datos. El aprendizaje automático permite que los sistemas informáticos se ajusten y mejoren continuamente a medida que acumulan más \"experiencias\". Por lo tanto, el rendimiento de estos sistemas puede mejorar si se proporcionan conjuntos de datos más grandes y variados para su procesamiento.\n",
        "\n",
        "Cuando se entrenan modelos de machine learning, cada conjunto de datos y cada modelo necesitan un conjunto diferente de \"hiperparámetros\".\n",
        "Los hiperparámetros son variables de configuración externa que se utilizan para administrar el entrenamiento de modelos de machine learning. Controlan de forma directa la estructura, funciones y rendimiento de los modelos.\n",
        "Los hiperparámetros son los parámetros de un modelo de aprendizaje automático, que no se aprenden durante el entrenamiento, sino que se establecen antes de que comience.\n",
        "\n",
        "El \"ajuste de hiperparámetros\" permite modificar el rendimiento del modelo para lograr resultados óptimos. Este proceso es una parte fundamental del machine learning.\n",
        "El ajuste de hiperparámetros puede ser manual o automático. A pesar de que el ajuste manual es lento y tedioso, permite entender mejor cómo afectan al modelo las ponderaciones de los hiperparámetros. El proceso de ajuste de hiperparámetros es iterativo, y debe probar diferentes combinaciones de parámetros y valores.\n",
        "\n",
        "En el aprendizaje automático es importante utilizar técnicas de \"validación cruzada\" , de modo que el modelo no se centre únicamente en una única porción de sus datos.\n",
        "La validación cruzada o cross-validation es una técnica utilizada para evaluar los resultados de un análisis estadístico y garantizar que son independientes de la partición entre datos de entrenamiento y prueba.\n",
        "La idea básica de la validación cruzada es dividir los datos en conjuntos de entrenamiento y validación, y luego entrenar el modelo en el conjunto de entrenamiento y evaluar su rendimiento en el conjunto de validación. Este proceso se repite varias veces, con diferentes subconjuntos de los datos utilizados para el entrenamiento y la validación, y se calcula el rendimiento promedio.\n",
        "\n",
        "En los procesos de machine learning supervisado se utilizan diversos algoritmos y técnicas de cálculo, generalmente calculados mediante el uso de programas como R o Python.\n",
        "\n",
        "Dependiendo del tipo de datos que se usen para el entrenamiento, será de modelo de aprendizaje automático que se use.\n",
        "A grandes rasgos, existen tres tipos de modelos que se usan en el aprendizaje automático: aprendizaje supervisado , no supervisado y por refuerzo.\n",
        "\n",
        "Consultando el trabajo de otros investigadores, se observa que utilizan principalmente el aprendizaje automático supervisado.\n",
        "Este tipo aprendizaje supervisado utiliza un conjunto de entrenamiento para enseñar a los modelos a producir el resultado deseado. Este conjunto de datos de entrenamiento incluye entradas y salidas correctas, que permiten al modelo aprender con el tiempo. El algoritmo mide su precisión a través de la función de pérdida, ajustando hasta que el error se haya minimizado lo suficiente.\n",
        "\n",
        "Yang Zhe y otros, utilizaron como datos de entrada la reflectancia de superficie y datos de salida la turbidez, utilizaron los modelos SVR (support vector regression), random forest (RF) y eXtreme Gradiente Boostring (XGBoost).\n",
        "Los hiperparámetros de cada modelo se determinaron mediante una búsqueda en cuadrícula de validación cruzada en Scikit-Learn de Python [@Yang2023].\n",
        "\n",
        "Ma Yue y otros, utilizaron varios modelos de aprendizaje automático, usaron Python 3.7 tanto para la predicción de la turbidez del agua y la optimización de la los hiperparámetros [@Ma2021].\n",
        "\n",
        "Zhao y otros probaron 14 modelos de machine learning en un estanque de peces con un dispositivo de construction propia, de los cuales ETR, Bagging, RFR, and ABR son los que presentaron un mejor desempeño en la estimación de la turbidez. Los algoritmos se implementaron utilizando Python 3.6 y bibliotecas de aprendizaje\n",
        "scikit [@Zhao2022].\n",
        "\n",
        ":::: {.content-visible when-format=\"html\"}\n",
        "\n",
        "::: {.column-screen-right}\n",
        "\n",
        "|Modelo de machine learning|Cuerpo de agua|Métricas|Plataforma| Referencia |\n",
        "|:--|:--|:--|:--|:-:|\n",
        "|SVR, ELM ,BP ,CART ,GBT ,RF ,KNN|Lagos|RMSE, $R^{2}$, MAE|Sentinel-MSI|@Ma2021|\n",
        "|eXtreme Gradient Boosting (XGBoost),  support vector regression (SVR), random forest (RF)|Lago|RMSE, $R^{2}$, MAPE| Sentinel-2A/B y Landsat-8/9 |  @Yang2023 |\n",
        "| linear regression (LR), ridge regression (RR),  least absolute shrinkage and selection operator regression(LASSO), elastic net regression (ENR),  k-nearest neighbor regression (KNN), Gaussian process regression (GPR), decision tree regression (DTR), support vector regression (SVR), multilayer perceptron regression (MLP), adaptive boosting regression (ABR), gradient boosting regression (GBR), bootstrap aggregating regression (Bagging), random forest regression (RFR), and extreme tree regression (ETR) | Estanque de peces | MAE, MRSE, MAPE, $R^{2}$, RE, Acc |Propia| @Zhao2022 |\n",
        "\n",
        ": Características principales de algoritmos de aprendizaje automático para la estimación de turbidez. {#tbl-turb-machine .striped .hover tbl-colwidths=\"[50,13,13,14,10]\"}\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "# Procesamiento de datos\n",
        "\n",
        "Para el procesamiento de los datos se utilizará la librería *pandas* de Python.\n",
        "\n",
        "En el proyecto tenemos dos archivos .csv que contienen los datos:\n",
        "\n",
        "-base_de_datos_lab.csv → contiene resultados de laboratorio \n",
        "\n",
        "-base_de_datos_gis.csv → contiene datos espectrales\n",
        "\n",
        "**Importamos la librería *pandas* para usarla, la nombramos como \"pd\" para simplificar**"
      ],
      "id": "59a49cad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd"
      ],
      "id": "9adab560",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Leemos los archivos .csv por separado y definimos dos DataFrame**\n",
        "\n",
        "Un DataFrame es basicamente una tabla, donde la información se organiza en filas y columnas. Los datos de la misma columna contienen el mismo tipo de datos, pandas agrega por defecto un \"índice\" que nos ayuda a identificar una fila en particular.\n",
        "\n",
        "Con la función *pd.read_csv* le idicamos a pandas que queremos leer archivos .csv."
      ],
      "id": "dba7ebca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df1_lab = pd.read_csv(r\"D:\\GIT\\Turbidez\\datos\\base_de_datos_lab.csv\")\n",
        "df2_gis = pd.read_csv(r\"D:\\GIT\\Turbidez\\datos\\base_de_datos_gis.csv\")"
      ],
      "id": "253c8da7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**df1_lab** DataFrame de datos provenientes del laboratorio.\n",
        "\n",
        "**df2_gis** DataFrame de datos espectrales provenientes del sensor MSI de Sentinel-2.\n",
        "\n",
        "**Nota:** Se debió colocar la \"r\" delante de la dirección para que lea los archivos.\n",
        "\n",
        "Video de YouTube [¿Qué es un DataFrame?](https://www.youtube.com/watch?v=LnH_STJ2GXo)  \n",
        "\n",
        "Verificamos que los datos se han leído y se crearon correctamente ambos DataFrame por separado, con *print* "
      ],
      "id": "88e1cc41"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(df1_lab.head())\n",
        "print(df2_gis)"
      ],
      "id": "afa4d3a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nota:** La primer columna (donde se ven los valores 0,1,2,3,4, ...) es el *índice* que agrega pandas por defecto al DataFrame, esa columna no forma parte del csv original.\n",
        "\n",
        "**Hacemos un filtrado en el DataFrame de datos espectrales**\n",
        "\n",
        "En la tabla original de los datos espectrales en la columna *pixel* se menciona 1x1 y 3x3. Cada píxel contiene un valor de reflectancia medida por el sensor de Sentinel-2.\n",
        "\n",
        "El valor de reflectancia de un único píxel (1x1) puede estar afectado por el de los píxeles adyacentes. Para considerar este efecto, se reliazó una grila de 3x3 aldedor del pixel central. Luego se calcula el promedio de la reflectancia de todos los píxeles (incluído el central). Tomamos este valor promedio para nuestro estudio, por lo que se conservan unicamente las filas donde pixel=3x3, \n",
        "\n",
        "**IMPORTANTE**: Esta etapa es necesaria realizarla, porque hay valores de reflectancia tanto para píxles de 1x1 y de 3x3, y a la hora de operar con la tabla la librería *pandas* tomará ambos valores y realizará cálculos erroneos.\n",
        "\n",
        "Para esto, realizamos un filtrado y creamos un nuevo DataFrame **\"df_gis3x3\"**, el cual se obtiene al hacer un filtrado en el DataFrame original. "
      ],
      "id": "3ff38a83"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_gis3x3 = df2_gis[(df2_gis['pixel'] == '3x3')]\n",
        "print(df_gis3x3.head())"
      ],
      "id": "4aff7cd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nota:** se conserva el índice del original\n",
        "\n",
        "**Combinamos ambos DataFrame para tener los datos en una única base de datos.**\n",
        "\n",
        "Lo defimos como **df_combinado**, para esto utilizamos la función *pd.merge* para realizar la combinación."
      ],
      "id": "c39146a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_combinado = pd.merge(df1_lab, df_gis3x3, on=['latitud', 'longitud','fecha'], how='inner')"
      ],
      "id": "3e3c28a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**on=['latitud', 'longitud','fecha']**\tEspecifica las columnas por las cuales se unirán los dos DataFrames. En este caso, por coincidencias exactas en latitud, longitud y fecha.\n",
        "\n",
        "**how='inner'**\tEs el tipo de unión, significa que solo se conservarán las filas que tengan coincidencias en ambos DataFrames en las columnas mencionadas.\n",
        "\n",
        "Verificamos que la combinacion se haya realizado correctamente"
      ],
      "id": "5916b071"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(df_combinado.head())"
      ],
      "id": "a063148d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Filtramos la turbidez del DataFrame**\n",
        "\n",
        "Del DataFrame combinado, solo nos interesa las filas que contengan los valores de turbidez, ya que es la propiedad de estudio en este sitio web. Por ello nos quedamos con las filas en donde la columna *param* sea igual a *turb*.\n",
        "\n",
        "Creamos un nuevo DataFrame a partir de *df_combinado*."
      ],
      "id": "db8d3aa6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_turbidez = df_combinado[(df_combinado['param'] == 'turb')]"
      ],
      "id": "a2966e39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Verificamos"
      ],
      "id": "8c0cb3be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(df_turbidez.head())"
      ],
      "id": "bba6b4fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nota:** Se han eliminado las filas de ph, cond, sol_sus, etc. Se conserva el índice del DataFrame original.\n",
        "\n",
        "**Eliminamos las columnas que no nos interesan**\n",
        "\n",
        "Creamos un nuevo DataFrame a partir de *df_turbidez*. Con la función **.drop** especificamos que columnas queremos eliminar."
      ],
      "id": "b06b6b3a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_turbidez_banda = df_turbidez.drop(columns=['longitud','latitud','punto','pixel','fecha','param'])\n",
        "\n",
        "print(df_turbidez_banda.head())"
      ],
      "id": "a6b0fe47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nota:** Solo nos quedamos con las columnas valor,banda y reflect.\n",
        "\n",
        "**Cambiamos el nombre de la columna \"valor\" por el de \"turbidez\"**\n",
        "Como los valores de esa columna son de turbidez, directamente cambiamos el nombre de la columna con la función **.rename**"
      ],
      "id": "46ad0c19"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_turbidez_banda.rename(columns={'valor': 'turbidez'}, inplace=True)\n",
        "\n",
        "print(df_turbidez_banda.head())"
      ],
      "id": "20bb4716",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Creamos la tabla final**\n",
        "\n",
        "Usamos la función **.pivot_table** para que las columnas sean la turbidez y las distintas bandas de Sentinel-2 (B01, B02 , B03...)"
      ],
      "id": "1edbc62f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_final = df_turbidez_banda.pivot_table(\n",
        "    index='turbidez',\n",
        "    columns='banda',\n",
        "    values='reflect',  \n",
        "    )"
      ],
      "id": "93839825",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¿Qué significa cada término en el argumento de la función pivot_table?\n",
        "\n",
        "index='turbidez' → Las filas serán los valores únicos de 'turbidez'\n",
        "\n",
        "columns='banda'  → Las columnas serán los valores únicos de 'banda' (B01, B02...)\n",
        "\n",
        "values='reflect' → El contenido de la tabla será lo que haya en la columna 'reflect'\n",
        "\n",
        "**Creamos archivo final con los valores de turbidez y reflectancia de cada banda**\n",
        "\n",
        "***-Forma 1***\n",
        "Creamos un .csv con los datos que nos interesan con la función **.to_csv**"
      ],
      "id": "4ecb2057"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        " df_final.to_csv('Turbidez_FINAL.csv', index=True)"
      ],
      "id": "3b8325f8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**IMPORTANTE:** **index=True** , debe ser así para que el índice que definimos al pivotar sea una columna visible en el archivo csv.\n",
        "\n",
        "Recordemos que la columna **index** es solo visible solo por la librería *pandas*, \n",
        "Si guardamos con **index=False**, se omite y no se guarda en el csv.\n",
        "\n",
        "***-Forma 2***\n",
        "Si decidimos poner **index=False** tenemos que usar una función adicional antes de exportar, debido a que la turbidez está en el índice, no como una columna.\n",
        "\n",
        "Por lo tanto, luego de hacer el pivot se debe agregar una línea de código."
      ],
      "id": "68a53d7f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_final = df_turbidez_banda.pivot_table(\n",
        "    index='turbidez',\n",
        "    columns='banda',\n",
        "    values='reflect',  \n",
        "    )\n",
        "\n",
        "df_final = df_final.reset_index() #Línea de código que se debe agregar"
      ],
      "id": "623bd81f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**reset_index()** convierte el índice definido previamente como \"turbidez\" en una columna normal y reemplaza el índice por uno numérico estándar (0, 1, 2...). que es el predeterminado por pandas.\n",
        "\n",
        "Finalmente exportamos como archivo csv."
      ],
      "id": "3ceac7aa"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_final.to_csv('Turbidez_FINAL2.csv', index=False)"
      ],
      "id": "6fc7a949",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Verificación tabla final**"
      ],
      "id": "c9a1e09b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(r'D:\\GIT\\Turbidez\\Turbidez_FINAL.csv')\n",
        "print(df.head())"
      ],
      "id": "9a85fffd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prueba de modelo lineal\n",
        "\n",
        "**Regresión lineal con método de mínimos cuadrados**\n",
        "\n",
        "Reemplamos el código del tutorial de sklearn por nuestros datos.\n",
        "\n",
        "Debemos importar las funciones necesarias para:\n",
        "\n",
        "1- Leer el archivo .csv creado previamente , que contiene los datos de turbidez y los valores de reflectancia para cada banda.\n",
        "\n",
        "2- Para usar el método de mínimos cuadrados\n",
        "\n",
        "**Importamos las funciones**"
      ],
      "id": "f3e5bd21"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "6a6851af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*pandas* → para leer los datos\n",
        "\n",
        "*train_test_split* → para dividir los datos en entrenamiento y validación\n",
        "\n",
        "*LinearRegression* → para crear el modelo de regresión lineal\n",
        "\n",
        "*mean_squared_error* y *r2_score* → Para medir el desempeño del modelo (RMSE y R2)\n",
        "\n",
        "*matplotlib.pyplot* → para realizar gráficos\n",
        "\n",
        "**Leemos los datos de interés y los dividimos en entrenamiento y validación.**\n",
        "\n",
        "Lectura de datos, lo hacemos con *pd.read_csv*"
      ],
      "id": "2ec53822"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df = pd.read_csv(r\"D:\\GIT\\Turbidez\\Turbidez_FINAL.csv\")\n",
        "\n",
        "X = df[['B05']]  \n",
        "y = df['turbidez']  "
      ],
      "id": "39d3a6fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos: \n",
        "\n",
        "**df**, un DataFrame que contiene los datos de turbidez y reflectancia;\n",
        "\n",
        "**X** para que sea los valores de reflectancia de una banda en particular;\n",
        "\n",
        "**y** para que sea la turbidez.\n",
        "\n",
        "**Dividimos en datos para el entrenamiento y validación**"
      ],
      "id": "2642da5c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X, y, test_size=0.25, shuffle=True, random_state=42 \n",
        ")"
      ],
      "id": "3c123635",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conjunto de datos para el entrenamiento\n",
        "**X_train** y **X_test**\n",
        "\n",
        "Conjunto de datos para la validación\n",
        "**y_train** y **y_test**\n",
        "\n",
        "**Creamos el modelo de regresión**"
      ],
      "id": "a3f1e215"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regressor = LinearRegression().fit(X_train, y_train)"
      ],
      "id": "82438d4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LinearRegression()** Crea el modelo de regresión lineal llamado \"*regressor*\". Este modelo, se entrena con la función **.fit** a partir de los datos de entrenamiento (X_train, y_train)\n",
        "\n",
        "\n",
        "**Evaluamos el modelo generado a partir de las métricas de desempeño.**"
      ],
      "id": "372df797"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "p_rmse = mean_squared_error(y_test, y_pred)\n",
        "p_r2 = r2_score(y_test, y_pred)"
      ],
      "id": "7e6fd25c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con la función **print** visualizamos los valores de las métricas de desempeño"
      ],
      "id": "ac560719"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"RMSE\", p_rmse) \n",
        "print(\"R2\", p_r2)"
      ],
      "id": "bb873688",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para ver la ecuación del modelo de regresión"
      ],
      "id": "fd207e02"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Coeficientes (pendientes)\n",
        "coef = regressor.coef_\n",
        "\n",
        "# Intercepto (ordenada al origen)\n",
        "intercept = regressor.intercept_\n",
        "\n",
        "print(f\"La ecuación es: y = {coef[0]:.3f}x + {intercept:.3f}\")"
      ],
      "id": "f455d8fa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Visualizamos los resultados comparando el conjunto de entrenamiento y validación.**"
      ],
      "id": "cd776fba"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)\n",
        "\n",
        "#Gráfico de entrenamiento\n",
        "ax[0].plot(\n",
        "    X_train,\n",
        "    regressor.predict(X_train),\n",
        "    linewidth=3,\n",
        "    color=\"#17A77E\",\n",
        "    label=\"Modelo\",\n",
        ")\n",
        "\n",
        "ax[0].scatter(X_train, y_train, label=\"Entrenamiento\", color = \"#9D50A6\", alpha = .6)\n",
        "ax[0].set(xlabel=\"Banda 5\", ylabel=\"Turbidez\", title=\"Conjunto de entrenamiento\")\n",
        "ax[0].legend()\n",
        "\n",
        "#Gráfico de validación\n",
        "ax[1].plot(X_test, y_pred, linewidth=3, color=\"#17A77E\", label=\"Modelo\")\n",
        "ax[1].scatter(X_test, y_test, label=\"Validación\", color = \"#9D50A6\", alpha = .6)\n",
        "ax[1].set(xlabel=\"Banda 5\", ylabel=\"Turbidez\", title=\"Conjunto de validación\")\n",
        "ax[1].legend()\n",
        "\n",
        "#Ecuación de la recta\n",
        "coef = regressor.coef_[0]\n",
        "intercept = regressor.intercept_\n",
        "equation = f\"y = {coef:.2f}x + {intercept:.2f}\"\n",
        "# Mostrar la ecuación en ambos subgráficos (opcionalmente, puedes usar solo uno)\n",
        "for a in ax:\n",
        "    a.text(0.05, 0.95, equation, transform=a.transAxes,\n",
        "           fontsize=10, verticalalignment='top',\n",
        "           bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
        "\n",
        "fig.suptitle(\"Regresión lineal\")\n",
        "\n",
        "plt.show()"
      ],
      "id": "874fce1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pruebas de correlación\n",
        "## Prueba de correlación C1: turbidez vs bandas\n",
        "Para ser mas rigurosos, agregamos mas etapas durante el entrenamiento de nuestro modelo lineal.\n",
        "\n",
        "**Importamos *pandas* para leer los datos**"
      ],
      "id": "505b427c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import pandas as pd\n",
        "\n",
        "Datos= pd.read_csv(r'D:\\GIT\\Turbidez\\Turbidez_FINAL.csv')\n",
        "#print (Datos.head())"
      ],
      "id": "f47a0271",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Calculamos coeficiente de correlacion lineal \"r\" entre la turbidez y cada banda con la función *.corr* de pandas.** \n",
        "\n",
        "Esta medida indica cuanto se relacionan dos variables, puede tomar valores desde -1 a +1: \n",
        "\n",
        "• +1 correlación lineal perfecta positiva.\n",
        "\n",
        "•  0 sin correlación.\n",
        "\n",
        "• -1 correlación lineal perfecta negativa."
      ],
      "id": "e81810d1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "bandas = [col for col in Datos.columns if col.startswith('B')]\n",
        "\n",
        "correlaciones = {}\n",
        "\n",
        "for banda in bandas:\n",
        "    r = Datos['turbidez'].corr(Datos[banda])\n",
        "    correlaciones[banda] = r\n",
        "\n",
        "#Creamos un Data Frame.\n",
        "df_correlaciones1 = pd.DataFrame(list(correlaciones.items()), columns=['Banda', 'r'])\n",
        "#Ordenamos por mayor a menos valor de r.\n",
        "df_correlaciones1 = df_correlaciones1.sort_values(by='r', ascending=False).reset_index(drop=True)\n",
        "\n",
        "df_correlaciones1['Banda'] = \"turb vs \" + df_correlaciones1['Banda'].astype(str)\n",
        "df_correlaciones1.rename(columns={'Banda': 'Correlación 1'}, inplace=True)\n",
        "\n",
        "df_correlaciones1.to_csv(r'D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C1_turb_vs_banda.csv', index=False)\n",
        "\n",
        "df_correlaciones1"
      ],
      "id": "011f7c04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que el mejor valor se obtiene con **turb vs B05 = 0.8719**\n",
        "\n",
        "**Gráfica**"
      ],
      "id": "593d21d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(Datos['B05'], Datos['turbidez'], color='blue', alpha=0.7)\n",
        "plt.xlabel('B05')\n",
        "plt.ylabel('Turbidez')\n",
        "plt.title('Turbidez vs B05')\n",
        "plt.grid(True)\n",
        "\n",
        "descripcion = \"Figura 1: Este gráfico de dispersión muestra la relación entre la banda espectral B05 y la turbidez del agua.\"\n",
        "plt.figtext(0.5, -0.04, descripcion,\n",
        "            wrap=True,                  # Permite que el texto se ajuste en varias líneas\n",
        "            horizontalalignment='center', # Centra el texto horizontalmente\n",
        "            fontsize=9,                 # Tamaño de la fuente\n",
        "            color='gray'                # Color del texto (comúnmente gris para pies de figura)\n",
        "           )\n",
        "\n",
        "plt.show()"
      ],
      "id": "8c09fd82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prueba de correlación C2: ln(turbidez) vs bandas\n",
        "\n",
        "**Importamos *nunpy* para operar con funciones matemáticas**\n",
        "\n",
        "Creamos un nuevo DataFrame para aplicarle el logaritmo a la colomna turbidez "
      ],
      "id": "80e6d5e8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import numpy as np\n",
        "\n",
        "Datos_turb_log = pd.read_csv(r'D:\\GIT\\Turbidez\\Turbidez_FINAL.csv')\n",
        "Datos_turb_log['turbidez'] = np.log(Datos_turb_log['turbidez'])\n",
        "\n",
        "#Cambio el nombre la columna \"turbidez\" luego de aplicar el logaritmo\n",
        "Datos_turb_log = Datos_turb_log.rename(columns={'turbidez': 'ln_turbidez'})\n",
        "\n",
        "#print(Datos_turb_log.head())"
      ],
      "id": "816e5bb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos *r* entre el ln_turb y cada banda, con la función **.corr** de pandas. "
      ],
      "id": "1f247d81"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "bandas = [col for col in Datos_turb_log.columns if col.startswith('B')]\n",
        "\n",
        "correlaciones = {}\n",
        "\n",
        "for banda in bandas:\n",
        "    r = Datos_turb_log['ln_turbidez'].corr(Datos_turb_log[banda])\n",
        "    correlaciones[banda] = r\n",
        "\n",
        "#Creamos un Data Frame.\n",
        "df_correlaciones2 = pd.DataFrame(list(correlaciones.items()), columns=['Banda', 'r'])\n",
        "#Ordenamos por mayor a menos valor de r.\n",
        "df_correlaciones2 = df_correlaciones2.sort_values(by='r', ascending=False).reset_index(drop=True)\n",
        "\n",
        "df_correlaciones2['Banda'] = \"ln_turb vs \" + df_correlaciones2['Banda'].astype(str)\n",
        "df_correlaciones2.rename(columns={'Banda': 'Correlación 2'}, inplace=True)\n",
        "\n",
        "df_correlaciones2.to_csv(r'D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C2_ln_turb_vs_banda.csv', index=False)\n",
        "\n",
        "df_correlaciones2"
      ],
      "id": "ebd89fb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que el mejor valor se obtiene con **ln_turb vs B05 = 0.7267**\n",
        "\n",
        "**Gráfica**"
      ],
      "id": "d1aabf12"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(Datos_turb_log['B05'], Datos_turb_log['ln_turbidez'], color='blue', alpha=0.7)\n",
        "plt.xlabel('B05')\n",
        "plt.ylabel('ln(turbidez)')\n",
        "plt.title('ln(turbidez) vs B05')\n",
        "plt.grid(True)\n",
        "\n",
        "descripcion = \"Figura 2: Este gráfico de dispersión muestra la relación entre la banda espectral B05 y logaritmo de la turbidez del agua. Se observa poca linealidad entre ambas.\"\n",
        "plt.figtext(0.5, -0.06, descripcion,\n",
        "            wrap=True,                  # Permite que el texto se ajuste en varias líneas\n",
        "            horizontalalignment='center', # Centra el texto horizontalmente\n",
        "            fontsize=9,                 # Tamaño de la fuente\n",
        "            color='gray'                # Color del texto (comúnmente gris para pies de figura)\n",
        "           )\n",
        "\n",
        "plt.show()"
      ],
      "id": "d61008df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prueba de correlación C3: turbidez vs ln(bandas)\n",
        "\n",
        "**Importamos *nunpy* para operar con funciones matemáticas**\n",
        "\n",
        "Creaamos un nuevo DataFrame para aplicarle el logaritmo a todas las columnas "
      ],
      "id": "a1da488b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "Banda_log = pd.read_csv(r'D:\\GIT\\Turbidez\\Turbidez_FINAL.csv')\n",
        "\n",
        "col = [col for col in Banda_log.columns if col.startswith('B')]\n",
        "\n",
        "Banda_log[col] = np.log(Banda_log[col])\n",
        "\n",
        "#Cambiamos en nombre las columnas, agremamos ln_ a cada columna\n",
        "\n",
        "Banda_log.columns = ['ln_' + col for col in Banda_log.columns]\n",
        "\n",
        "Banda_log.rename(columns={'ln_turbidez': 'turbidez'}, inplace=True)\n",
        "\n",
        "Banda_log.to_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Datos_turb_banda\\turb_vs_ln_banda.csv\", index=False)\n",
        "\n",
        "#print(Banda_log.head())"
      ],
      "id": "284fe427",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos *r* entre el ln_turb y ln de cada banda, con la función **.corr** de pandas. "
      ],
      "id": "3f7bef3f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "bandas_ln = [col for col in Banda_log.columns if col.startswith('ln_B')]\n",
        "\n",
        "correlaciones = {}\n",
        "\n",
        "for banda in bandas_ln:\n",
        "    r = Banda_log['turbidez'].corr(Banda_log[banda])\n",
        "    correlaciones[banda] = r\n",
        "\n",
        "#Creamos un Data Frame.\n",
        "df_correlaciones3 = pd.DataFrame(list(correlaciones.items()), columns=['Banda', 'r'])\n",
        "#Ordenamos por mayor a menos valor de r.\n",
        "df_correlaciones3 = df_correlaciones3.sort_values(by='r', ascending=False).reset_index(drop=True)\n",
        "\n",
        "df_correlaciones3['Banda'] = \"turb vs \" + df_correlaciones3['Banda'].astype(str)\n",
        "df_correlaciones3.rename(columns={'Banda': 'Correlación 3'}, inplace=True)\n",
        "\n",
        "\n",
        "df_correlaciones3.to_csv(r'D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C3_turb_vs_ln_banda.csv', index=False)\n",
        "\n",
        "df_correlaciones3"
      ],
      "id": "b39cbe31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que el mejor valor se obtiene con **turb vs ln_B05  0.8320**\n",
        "\n",
        "**Gráfica**"
      ],
      "id": "80fccebe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(Banda_log['ln_B05'], Banda_log['turbidez'], color='blue', alpha=0.7)\n",
        "plt.xlabel('ln(B05)')\n",
        "plt.ylabel('turbidez')\n",
        "plt.title('turbidez vs de ln(B05)')\n",
        "plt.grid(True)\n",
        "\n",
        "descripcion = \"Figura 3: Este gráfico de dispersión muestra la relación entre ln(B05) y turbidez. Se observa una mejora de la linealidad entre ambas.\"\n",
        "plt.figtext(0.5, -0.04, descripcion,\n",
        "            wrap=True,                  # Permite que el texto se ajuste en varias líneas\n",
        "            horizontalalignment='center', # Centra el texto horizontalmente\n",
        "            fontsize=9,                 # Tamaño de la fuente\n",
        "            color='gray'                # Color del texto (comúnmente gris para pies de figura)\n",
        "           )\n",
        "\n",
        "plt.show()"
      ],
      "id": "f750ddfa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prueba de correlación C4: ln(turbidez) vs ln(bandas)\n",
        "\n",
        "**Importamos *nunpy* para operar con funciones matemáticas**\n",
        "\n",
        "Creaamos un nuevo DataFrame para aplicarle el logaritmo a todas las columnas "
      ],
      "id": "f30b8f14"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import numpy as np\n",
        "\n",
        "Datos_log = pd.read_csv(r'D:\\GIT\\Turbidez\\Turbidez_FINAL.csv')\n",
        "Datos_log = np.log(Datos_log)\n",
        "#Cambiamos en nombre las columnas, agremamos ln_ a cada columna\n",
        "Datos_log.columns = ['ln_' + col for col in Datos_log.columns]\n",
        "#print(Datos_log.head())"
      ],
      "id": "f9b506a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos *r* entre el ln_turb y ln de cada banda, con la función **.corr** de pandas. "
      ],
      "id": "c1e61c8e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "bandas_ln = [col for col in Datos_log.columns if col.startswith('ln_B')]\n",
        "\n",
        "correlaciones = {}\n",
        "\n",
        "for banda in bandas_ln:\n",
        "    r = Datos_log['ln_turbidez'].corr(Datos_log[banda])\n",
        "    correlaciones[banda] = r\n",
        "\n",
        "#Creamos un Data Frame.\n",
        "df_correlaciones4 = pd.DataFrame(list(correlaciones.items()), columns=['Banda', 'r'])\n",
        "#Ordenamos por mayor a menos valor de r.\n",
        "df_correlaciones4 = df_correlaciones4.sort_values(by='r', ascending=False).reset_index(drop=True)\n",
        "\n",
        "df_correlaciones4['Banda'] = \"ln_turb vs \" + df_correlaciones4['Banda'].astype(str)\n",
        "df_correlaciones4.rename(columns={'Banda': 'Correlación 4'}, inplace=True)\n",
        "\n",
        "df_correlaciones4.to_csv(r'D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C4_ln_turb_vs_ln_banda.csv', index=False)\n",
        "\n",
        "df_correlaciones4"
      ],
      "id": "e3a3b007",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observamos que el mejor valor se obtiene con **ln_turb vs ln_B05  0.7716**\n",
        "\n",
        "**Gráfica**"
      ],
      "id": "8b7aec01"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(Datos_log['ln_B05'], Datos_log['ln_turbidez'], color='blue', alpha=0.7)\n",
        "plt.xlabel('ln(B05)')\n",
        "plt.ylabel('ln(turbidez)')\n",
        "plt.title('ln(turbidez) vs de ln(B05)')\n",
        "plt.grid(True)\n",
        "\n",
        "descripcion = \"Figura 3: Este gráfico de dispersión muestra la relación entre ln(B05) y ln(turbidez).\"\n",
        "plt.figtext(0.5, -0.04, descripcion,\n",
        "            wrap=True,                  # Permite que el texto se ajuste en varias líneas\n",
        "            horizontalalignment='center', # Centra el texto horizontalmente\n",
        "            fontsize=9,                 # Tamaño de la fuente\n",
        "            color='gray'                # Color del texto (comúnmente gris para pies de figura)\n",
        "           )\n",
        "\n",
        "plt.show()"
      ],
      "id": "db3f0c7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Seleción de variables\n",
        "Se resume en una tabla las pruebas de correlación realizadas."
      ],
      "id": "92a90212"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import pandas as pd \n",
        "\n",
        "C1 = pd.read_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C1_turb_vs_banda.csv\")\n",
        "C2= pd.read_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C2_ln_turb_vs_banda.csv\")\n",
        "C3 = pd.read_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C3_turb_vs_ln_banda.csv\")\n",
        "C4 = pd.read_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Correlaciones\\C4_ln_turb_vs_ln_banda.csv\")\n",
        "\n",
        "C_comb = pd.concat([C1, C2 ,C3, C4], axis=1)\n",
        "\n",
        "C_comb"
      ],
      "id": "f2ef5f19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se puede observar que en C1 y C3 las correlaciones son mas altas respecto a C2 y C4. Por que que se seguirá el análisis con estas combinaciones:\n",
        "\n",
        "  • turb (bandas)\n",
        "\n",
        "  • turb (ln_bandas)\n",
        "\n",
        "Se probarán modelos con ambas combinaciones por separado y se evalurá su desempeño.\n",
        "\n",
        "Se utilizará *AIC* @Chatterjee2015, como criterio para la selección de variables.\n",
        "\n",
        "## Combinación 1: turb(bandas)"
      ],
      "id": "de0661b1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "Datos = pd.read_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Datos_turb_banda\\turb_vs_banda.csv\")\n",
        "\n",
        "# Variable objetivo\n",
        "y = Datos['turbidez']\n",
        "\n",
        "# Variable fija (B05 siempre presente)\n",
        "variables_fijas = ['B05']\n",
        "\n",
        "# Variables que se irán agregando en orden específico (según tabla de correlaciones 1)\n",
        "variables_a_agregar = ['B08', 'B07', 'B06', 'B04', 'B8A', 'B03', 'B02', 'B01', 'B12' , 'B11']  # Se puede agregar o cambiar el orden\n",
        "\n",
        "# Lista para guardar resultados\n",
        "resultados = []\n",
        "\n",
        "# Proceso de entrenamiento incremental\n",
        "for i in range(len(variables_a_agregar) + 1):\n",
        "    # Usamos solo las variables fijas al principio\n",
        "    variables_usadas = variables_fijas + variables_a_agregar[:i]\n",
        "\n",
        "    # Seleccionamos los datos correspondientes\n",
        "    X = Datos[variables_usadas]\n",
        "    \n",
        "    # División entrenamiento/prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)\n",
        "    \n",
        "    # Entrenar modelo\n",
        "    modelo = LinearRegression()\n",
        "    modelo.fit(X_train, y_train)\n",
        "    \n",
        "    # Predicción y evaluación\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "     # Cálculo de AIC\n",
        "    n = len(y_test)\n",
        "    residuals = y_test - y_pred\n",
        "    rss = np.sum(residuals ** 2)\n",
        "    k = X_test.shape[1] + 1  # +1 por el intercepto\n",
        "    aic = n * np.log(rss / n) + 2 * k\n",
        "  \n",
        "\n",
        "    # Guardamos los resultados como dict\n",
        "    resultados.append({\n",
        "        \"variables\": \", \".join(variables_usadas),\n",
        "        \"num_variables\": len(variables_usadas),\n",
        "        \"R2\": r2,\n",
        "        \"RMSE\": rmse,\n",
        "        \"AIC\": aic\n",
        "    })\n",
        "    \n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "df_resultados"
      ],
      "id": "8a7d263d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Gráfico de AIC**"
      ],
      "id": "ccaa0c31"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "aic_scores = [r[\"AIC\"] for r in resultados]\n",
        "n_vars = [r[\"num_variables\"] for r in resultados]\n",
        "\n",
        "plt.plot(n_vars, aic_scores, marker='o', color='purple')\n",
        "plt.title('AIC vs Número de Variables')\n",
        "plt.xlabel('Número de variables')\n",
        "plt.ylabel('AIC')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "638d34cb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combinación 2: turb(ln_bandas)."
      ],
      "id": "415e1b70"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "Datos = pd.read_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Datos_turb_banda\\turb_vs_ln_banda.csv\")\n",
        "\n",
        "#Variable objetivo\n",
        "y = Datos['turbidez']\n",
        "\n",
        "#Variable fija (B05 siempre presente)\n",
        "variables_fijas = ['ln_B05']\n",
        "\n",
        "#Variables que se irán agregando en orden específico (según tabla de correlaciones 3)\n",
        "variables_a_agregar = ['ln_B08', 'ln_B07', 'ln_B06', 'ln_B04', 'ln_B8A', 'ln_B03', 'ln_B02', 'ln_B01', 'ln_B12' , 'ln_B11']\n",
        "\n",
        "#Lista para guardar resultados\n",
        "resultados = []\n",
        "\n",
        "#Proceso de entrenamiento incremental\n",
        "for i in range(len(variables_a_agregar) + 1):\n",
        "    # Usamos solo las variables fijas al principio\n",
        "    variables_usadas = variables_fijas + variables_a_agregar[:i]\n",
        "\n",
        "    # Seleccionamos los datos correspondientes\n",
        "    X = Datos[variables_usadas]\n",
        "    \n",
        "    # División entrenamiento/prueba\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)\n",
        "    \n",
        "    # Entrenar modelo\n",
        "    modelo = LinearRegression()\n",
        "    modelo.fit(X_train, y_train)\n",
        "    \n",
        "    # Cálculo de R² y RMSE\n",
        "            r2 = r2_score(y_test, y_pred)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "            # Cálculo de R² ajustado\n",
        "            n_fold = len(y_test) # Número de observaciones\n",
        "            p = len(variables) if variables else 0 # Número de variables predictoras\n",
        "            if n_fold > p + 1: # Si el número de variables predictoras es igual al número de observaciones, no puede calcularse el R² ajustado\n",
        "                r2_ajustado = 1 - (1 - r2) * (n_fold - 1) / (n_fold - p - 1)\n",
        "            else:\n",
        "                r2_ajustado = np.nan\n",
        "\n",
        "            # Calculo el AIC\n",
        "            if mse > 0:\n",
        "                aic = n_fold * np.log(mse) + 2*k\n",
        "            else: \n",
        "                aic = np.nan\n",
        "\n",
        "\n",
        "    # Guardamos los resultados\n",
        "    resultados.append({\n",
        "        \"variables\": \", \".join(variables_usadas),\n",
        "        \"num_variables\": len(variables_usadas),\n",
        "        \"R2\": r2,\n",
        "        \"RMSE\": rmse,\n",
        "        \"AIC\": aic\n",
        "    })\n",
        "    \n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "df_resultados"
      ],
      "id": "43f148c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Gráfico de AIC**"
      ],
      "id": "af67a371"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "aic_scores = [r[\"AIC\"] for r in resultados]\n",
        "n_vars = [r[\"num_variables\"] for r in resultados]\n",
        "\n",
        "plt.plot(n_vars, aic_scores, marker='o', color='purple')\n",
        "plt.title('AIC vs Número de Variables')\n",
        "plt.xlabel('Número de variables')\n",
        "plt.ylabel('AIC')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "97dbe930",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamos el modelo lineal con el método de mínimos cudrados\n",
        "\n",
        "**Importamos las funciones**"
      ],
      "id": "71fc259f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "d3d91109",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dividimos los datos en entrenamiento y validación.**"
      ],
      "id": "00ca72c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = Datos_log[['ln_B05']]  \n",
        "y = Datos_log['ln_turbidez']  "
      ],
      "id": "d042ded7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos: \n",
        "\n",
        "**df**, un DataFrame que contiene los datos de turbidez y reflectancia;\n",
        "\n",
        "**X** para que sea los valores de reflectancia de una banda en particular;\n",
        "\n",
        "**y** para que sea la turbidez.\n",
        "\n",
        "**Dividimos en datos para el entrenamiento y validación**"
      ],
      "id": "b96ad1f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X, y, test_size=0.25, shuffle=True, random_state=42)\n",
        "\n",
        "#test_size=0.25 significa que usamos el 25% de los datos para el testeo y el %75 restante para el entrenamiento "
      ],
      "id": "63cee6e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conjunto de datos para el entrenamiento\n",
        "**X_train** y **X_test**\n",
        "\n",
        "Conjunto de datos para la validación\n",
        "**y_train** y **y_test**\n",
        "\n",
        "**Creamos el modelo de regresión**"
      ],
      "id": "852610b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regressor = LinearRegression().fit(X_train, y_train)"
      ],
      "id": "969963d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**LinearRegression()** Crea el modelo de regresión lineal llamado \"*regressor*\". Este modelo, se entrena con la función **.fit** a partir de los datos de entrenamiento (X_train, y_train)\n",
        "\n",
        "\n",
        "**Evaluamos el modelo generado a partir de las métricas de desempeño.**"
      ],
      "id": "359b4991"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "p_rmse = mean_squared_error(y_test, y_pred)\n",
        "p_r2 = r2_score(y_test, y_pred)"
      ],
      "id": "a56f49b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con la función **print** visualizamos los valores de las métricas de desempeño"
      ],
      "id": "f473b48e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"RMSE\", p_rmse) \n",
        "print(\"R2\", p_r2)"
      ],
      "id": "c0b8ee07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para ver la ecuación del modelo de regresión"
      ],
      "id": "b52d0480"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Coeficientes (pendientes)\n",
        "coef = regressor.coef_\n",
        "\n",
        "# Intercepto (ordenada al origen)\n",
        "intercept = regressor.intercept_\n",
        "\n",
        "print(f\"La ecuación es: y = {coef[0]:.3f}x + {intercept:.3f}\")"
      ],
      "id": "ba88c10d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Visualizamos los resultados comparando el conjunto de entrenamiento y validación.**"
      ],
      "id": "db3a3079"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)\n",
        "\n",
        "#Gráfico de entrenamiento\n",
        "ax[0].plot(\n",
        "    X_train,\n",
        "    regressor.predict(X_train),\n",
        "    linewidth=3,\n",
        "    color=\"#17A77E\",\n",
        "    label=\"Modelo\",\n",
        ")\n",
        "\n",
        "ax[0].scatter(X_train, y_train, label=\"Entrenamiento\", color = \"#9D50A6\", alpha = .6)\n",
        "ax[0].set(xlabel=\"ln_BO5\", ylabel=\"ln_turbidez\", title=\"Conjunto de entrenamiento\")\n",
        "ax[0].legend()\n",
        "\n",
        "#Gráfico de validación\n",
        "ax[1].plot(X_test, y_pred, linewidth=3, color=\"#17A77E\", label=\"Modelo\")\n",
        "ax[1].scatter(X_test, y_test, label=\"Validación\", color = \"#9D50A6\", alpha = .6)\n",
        "ax[1].set(xlabel=\"ln_BO5\", ylabel=\"ln_turbidez\", title=\"Conjunto de validación\")\n",
        "ax[1].legend()\n",
        "\n",
        "# Ecuación de la recta\n",
        "coef = regressor.coef_[0]\n",
        "intercept = regressor.intercept_\n",
        "equation = f\"y = {coef:.2f}x + {intercept:.2f}\"\n",
        "# Mostrar la ecuación en ambos subgráficos (opcionalmente, puedes usar solo uno)\n",
        "for a in ax:\n",
        "    a.text(0.05, 0.95, equation, transform=a.transAxes,\n",
        "           fontsize=10, verticalalignment='top',\n",
        "           bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
        "\n",
        "fig.suptitle(\"Regresión lineal\")\n",
        "\n",
        "plt.show()"
      ],
      "id": "70b472af",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento de modelo lineal multivariable\n"
      ],
      "id": "b6231168"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "Datos = pd.read_csv(r\"D:\\GIT\\Turbidez\\Datos creados\\Datos_turb_banda\\turb_vs_banda.csv\")\n",
        "X = Datos[['B05', 'B08', 'B07', 'B06', 'B04']]  \n",
        "y = Datos['turbidez']  \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, shuffle=True, random_state=42\n",
        ")\n",
        "\n",
        "modelo = LinearRegression()\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Métricas\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "#Ver coefidiones del modelo\n",
        "print(\"Intercepto:\", modelo.intercept_)\n",
        "print(\"Coeficientes:\")\n",
        "for nombre, coef in zip(X.columns, modelo.coef_):\n",
        "    print(f\"{nombre}: {coef:.4f}\")\n",
        "\n",
        "# Predicciones para entrenamiento y test\n",
        "y_train_pred = modelo.predict(X_train)\n",
        "y_test_pred = modelo.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Entrenamiento\n",
        "plt.scatter(y_train, y_train_pred, color='blue', label='Entrenamiento', alpha=0.6)\n",
        "\n",
        "# Test\n",
        "plt.scatter(y_test, y_test_pred, color='green', label='Test', alpha=0.6)\n",
        "\n",
        "# Línea ideal (y = x)\n",
        "min_val = min(min(y_train), min(y_test))\n",
        "max_val = max(max(y_train), max(y_test))\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2, label='Ideal')\n",
        "\n",
        "plt.xlabel('Turbidez real')\n",
        "plt.ylabel('Turbidez predicha')\n",
        "plt.title('Regresión Lineal: Valores Reales vs. Predichos')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "cff5d06c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Métodos de aprendizaje automático \n",
        "Proximamente...\n"
      ],
      "id": "363c4cfe"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt # Para visualización, opcional\n",
        "\n",
        "# 1. Cargar el dataset\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "\n",
        "# 2. Seleccionar múltiples variables (características)\n",
        "# En este caso, usaremos todas las características disponibles en el dataset de diabetes.\n",
        "# X ya contiene todas las características por defecto cuando no se selecciona nada.\n",
        "# Si quisieras seleccionar un subconjunto específico, lo harías como te mostré antes:\n",
        "# selected_features_indices = [0, 2, 5, 8] # Ejemplo: indices 0, 2, 5 y 8\n",
        "# X = X[:, selected_features_indices]\n",
        "\n",
        "print(f\"Dimensiones de X (características): {X.shape}\") # (número_muestras, número_características)\n",
        "print(f\"Dimensiones de y (objetivo): {y.shape}\")         # (número_muestras,)\n",
        "\n",
        "# 3. Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "# Es crucial tener un conjunto de prueba para evaluar el rendimiento del modelo en datos no vistos.\n",
        "# test_size=0.2 significa que el 20% de los datos se usarán para prueba.\n",
        "# random_state asegura que la división sea la misma cada vez que ejecutes el código, para reproducibilidad.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nDimensiones de X_train: {X_train.shape}\")\n",
        "print(f\"Dimensiones de X_test: {X_test.shape}\")\n",
        "print(f\"Dimensiones de y_train: {y_train.shape}\")\n",
        "print(f\"Dimensiones de y_test: {y_test.shape}\")\n",
        "\n",
        "# 4. Crear y entrenar el modelo de Regresión Lineal Múltiple\n",
        "# La clase LinearRegression de scikit-learn es la que necesitas.\n",
        "model = LinearRegression()\n",
        "\n",
        "# Entrenar el modelo con los datos de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 5. Hacer predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 6. Evaluar el rendimiento del modelo\n",
        "# Métricas comunes para regresión:\n",
        "\n",
        "# Error Cuadrático Medio (Mean Squared Error - MSE)\n",
        "# Mide el promedio de los cuadrados de los errores.\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"\\nError Cuadrático Medio (MSE): {mse:.2f}\")\n",
        "\n",
        "# Coeficiente de Determinación (R-squared o R2)\n",
        "# Indica la proporción de la varianza en la variable dependiente que es predecible a partir de las variables independientes.\n",
        "# Un valor de 1.0 indica que el modelo predice perfectamente la variable objetivo.\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Coeficiente de Determinación (R2): {r2:.2f}\")\n",
        "\n",
        "# Opcional: Analizar los coeficientes del modelo y el intercepto\n",
        "print(f\"\\nCoeficientes del modelo (pendientes para cada característica):\")\n",
        "# Los nombres de las características para el dataset de diabetes son:\n",
        "feature_names = load_diabetes().feature_names\n",
        "for i, coef in enumerate(model.coef_):\n",
        "    print(f\"  {feature_names[i]}: {coef:.2f}\")\n",
        "\n",
        "print(f\"Intercepto del modelo: {model.intercept_:.2f}\")\n",
        "\n",
        "# Opcional: Visualizar las predicciones vs. los valores reales\n",
        "# Esto es más fácil de visualizar con una sola característica,\n",
        "# pero con múltiples características puedes graficar predicciones vs. valores reales.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2) # Línea de identidad (predicciones perfectas)\n",
        "plt.xlabel(\"Valores Reales (y_test)\")\n",
        "plt.ylabel(\"Predicciones del Modelo (y_pred)\")\n",
        "plt.title(\"Valores Reales vs. Predicciones del Modelo de Regresión Lineal Múltiple\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "3d877f7c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\VICTOR\\AppData\\Local\\Programs\\Python\\Python313\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}